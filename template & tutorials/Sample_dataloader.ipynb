{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPMq6L3ypXjO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoObjectDetectionDataset(Dataset):\n",
        "    def __init__(self, video_frames_path, mask_files_path, transform=None):\n",
        "        self.video_frames_path = video_frames_path\n",
        "        self.mask_files_path = mask_files_path\n",
        "        self.transform = transform\n",
        "\n",
        "        self.frame_files = sorted(os.listdir(video_frames_path))\n",
        "        self.mask_files = sorted(os.listdir(mask_files_path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_file = os.path.join(self.video_frames_path, self.frame_files[idx])\n",
        "        mask_file = os.path.join(self.mask_files_path, self.mask_files[idx])\n",
        "\n",
        "        frame = cv2.imread(frame_file)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = (mask > 128).astype(np.uint8)  # Convert the mask to binary\n",
        "\n",
        "        sample = {'frame': frame, 'mask': mask}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "aZpKYZQ6pmnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeAndNormalize(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        frame, mask = sample['frame'], sample['mask']\n",
        "\n",
        "        frame = cv2.resize(frame, self.output_size, interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, self.output_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        frame = frame / 255.0\n",
        "        frame = frame.astype(np.float32)\n",
        "        frame = np.transpose(frame, (2, 0, 1))\n",
        "\n",
        "        return {'frame': frame, 'mask': mask}"
      ],
      "metadata": {
        "id": "Q88A9jvgpnB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_frames_path = \"path/to/video/frames\"\n",
        "mask_files_path = \"path/to/mask/files\"\n",
        "\n",
        "transform = ResizeAndNormalize(output_size=(224, 224))\n",
        "\n",
        "dataset = VideoObjectDetectionDataset(video_frames_path, mask_files_path, transform=transform)\n",
        "\n",
        "batch_size = 4\n",
        "num_workers = 4\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
      ],
      "metadata": {
        "id": "z0vO6iiXptqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tg8N-5dFpnEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hoxeKCuJpnGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}